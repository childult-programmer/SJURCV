{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lib\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base path\n",
    "image_path = 'C:/Users/RCV/RCV/week0912_panorama/images'\n",
    "save_path = 'C:/Users/RCV/RCV/week0912_panorama/panorama_image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Panorama:\n",
    "    def image_stitching(self, images, low_ratio=0.7, homo_Threshold=3.0, percent_Threshold=10, inlier_Threshold=50, is_percent=False, draw_matches=False, pano_draw_match_pair=True):        \n",
    "        panorama = None\n",
    "        \n",
    "        while len(images):\n",
    "            max_matched_image_index = self.find_max_matched_image(images, homo_Threshold, percent_Threshold, inlier_Threshold, is_percent, draw_matches)\n",
    "            max_matched_image = images[max_matched_image_index]\n",
    "            \n",
    "            if panorama is None:\n",
    "                panorama = max_matched_image\n",
    "            else:    \n",
    "                panorama = self.panorama_stitching(max_matched_image, panorama, pano_draw_match_pair)\n",
    "\n",
    "                cv2.imshow('panorama', panorama)\n",
    "                cv2.waitKey(0)\n",
    "\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "            del images[max_matched_image_index]\n",
    "            \n",
    "        return panorama\n",
    "\n",
    "\n",
    "    def computeSIFT(self, image):\n",
    "        img2gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        SIFT = cv2.SIFT_create()\n",
    "        kp, desc = SIFT.detectAndCompute(img2gray, None)\n",
    "\n",
    "        return kp, desc\n",
    "\n",
    "\n",
    "    def knn_match(self, desc_A, desc_B):\n",
    "        BF_matcher = cv2.BFMatcher(cv2.NORM_L1)\n",
    "        matches = BF_matcher.knnMatch(desc_A, desc_B, k=2)\n",
    "\n",
    "        return matches\n",
    "\n",
    "\n",
    "    def valid_match(self, matches, low_ratio):\n",
    "        valid_matches, valid_matches_idx = [], []\n",
    "        for m_A, m_B in matches:\n",
    "            if m_A.distance < m_B.distance * low_ratio:\n",
    "                valid_matches.append(m_A)\n",
    "                valid_matches_idx.append((m_A.trainIdx, m_A.queryIdx))\n",
    "\n",
    "        # print(f'BF matches: {len(matches)}, Good matches: {len(valid_matches)}')\n",
    "        return valid_matches, valid_matches_idx\n",
    "\n",
    "\n",
    "    def match_keypoints(self, kp_A, kp_B, desc_A, desc_B, low_ratio):\n",
    "        possible_matches = self.knn_match(desc_A, desc_B)\n",
    "        valid_matches, valid_matches_idx = self.valid_match(possible_matches, low_ratio=low_ratio)\n",
    "\n",
    "        # Coordinate match pairs need at least 4 pairs\n",
    "        if len(valid_matches) >= 4:\n",
    "            point_A, point_B = [], []\n",
    "            for train_idx, query_idx in valid_matches_idx:\n",
    "                point_A.append(np.float32(kp_A[query_idx].pt))\n",
    "                point_B.append(np.float32(kp_B[train_idx].pt))\n",
    "\n",
    "            point_A = np.asarray(point_A).reshape(-1, 1, 2)\n",
    "            point_B = np.asarray(point_B).reshape(-1, 1, 2)\n",
    "\n",
    "            return (point_A, point_B, valid_matches, valid_matches_idx)\n",
    "\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "\n",
    "    def draw_matches(self, image_A, kp_A, image_B, kp_B, matches):\n",
    "        draw = cv2.drawMatches(image_A, kp_A, image_B, kp_B, matches, None, flags=2)\n",
    "\n",
    "        return draw\n",
    "\n",
    "\n",
    "    # image_A = source, image_B = target\n",
    "    def find_homography(self, image_A, image_B, max_threshold=3.0):\n",
    "        # Compute SIFT\n",
    "        (kp_A, desc_A) = self.computeSIFT(image_A)\n",
    "        (kp_B, desc_B) = self.computeSIFT(image_B)\n",
    "            \n",
    "        # Get valid matches\n",
    "        matches = self.match_keypoints(kp_A, kp_B, desc_A, desc_B, low_ratio=0.7)\n",
    "\n",
    "        if matches is None:\n",
    "            return\n",
    "            \n",
    "        (point_A, point_B, valid_match, valid_match_idx) = matches\n",
    "\n",
    "        # mask has status of inliers and outliers\n",
    "        H, mask = cv2.findHomography(point_A, point_B, cv2.RANSAC, max_threshold)\n",
    "        matched_mask = mask.ravel().tolist()\n",
    "\n",
    "        return H, matched_mask\n",
    "\n",
    "\n",
    "    def find_matches_percent(self, matched_mask):\n",
    "        outlier, inlier = 0, 0\n",
    "\n",
    "        for mask in matched_mask:\n",
    "            if mask:\n",
    "                inlier += 1\n",
    "            else:\n",
    "                outlier += 1\n",
    "\n",
    "        percent = ((inlier) / (inlier + outlier)) * 100\n",
    "        # print(f'inlier: {inlier} / outlier: {outlier}')\n",
    "        \n",
    "        return percent\n",
    "\n",
    "    \n",
    "    def find_inlier_matches(self, matched_mask):\n",
    "        inlier = 0\n",
    "\n",
    "        for mask in matched_mask:\n",
    "            if mask:\n",
    "                inlier += 1\n",
    "\n",
    "        return inlier\n",
    "\n",
    "\n",
    "    def find_max_matched_with_pano(self, pano, image_list, homo_Threshold, percent_Threshold, inlier_Threshold, is_percent, draw_matches):\n",
    "        num_of_images = len(image_list)\n",
    "        max_matched_index, max_count = 0, 0\n",
    "\n",
    "        if num_of_images == 1:\n",
    "            return max_matched_index\n",
    "\n",
    "        for image_index, image in enumerate(image_list):\n",
    "            match_count = 0\n",
    "            if draw_matches:\n",
    "                # Compute SIFT\n",
    "                (kp_i, desc_i) = self.computeSIFT(image)\n",
    "                (kp_p, desc_p) = self.computeSIFT(pano)\n",
    "            \n",
    "                # Get valid matches\n",
    "                matches = self.match_keypoints(kp_i, kp_p, desc_i, desc_p, low_ratio=0.7)\n",
    "            \n",
    "                if matches is None:\n",
    "                    continue\n",
    "            \n",
    "                (point_A, point_B, valid_match, valid_match_idx) = matches   \n",
    "\n",
    "                draw = self.draw_matches(image, kp_i, pano, kp_p, valid_match)\n",
    "                \n",
    "                cv2.imshow('Match draw', draw)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "            # Compute homography, and Get perspective of image\n",
    "            _, matched_mask = self.find_homography(pano, image, homo_Threshold)\n",
    "            \n",
    "            if is_percent:\n",
    "                percent = self.find_matches_percent(matched_mask)\n",
    "                # print(f'A image index: {image_A_index} <-> {image_B_index}: B image index | matching percent: {percent}')\n",
    "\n",
    "                if percent > percent_Threshold: \n",
    "                    match_count += 1\n",
    "\n",
    "                if percent < 10: break\n",
    "\n",
    "            else:\n",
    "                num_of_inliers = self.find_inlier_matches(matched_mask)\n",
    "                # print(f'A image index: {image_A_index} <-> {image_B_index}: B image index | number of inliers : {num_of_inliers}')\n",
    "\n",
    "                if num_of_inliers > inlier_Threshold:\n",
    "                    match_count += 1\n",
    "\n",
    "            if max_count < match_count:\n",
    "                max_match_index = image_index\n",
    "                max_count = match_count \n",
    "\n",
    "        return max_match_index\n",
    "                    \n",
    "    \n",
    "    def find_max_matched_image(self, image_list, homo_Threshold, percent_Threshold, inlier_Threshold, is_percent, draw_matches):\n",
    "        num_of_images = len(image_list)\n",
    "        max_match_index, max_count = 0, 0\n",
    "\n",
    "        if num_of_images == 1:\n",
    "            return max_match_index\n",
    "\n",
    "        print(f'number of images: {num_of_images}')\n",
    "\n",
    "        for image_A_index in range(num_of_images):\n",
    "            match_count = 0\n",
    "            for image_B_index in range(num_of_images):\n",
    "                if image_A_index != image_B_index:\n",
    "                    if draw_matches:\n",
    "                        # Compute SIFT\n",
    "                        (kp_A, desc_A) = self.computeSIFT(image_list[image_A_index])\n",
    "                        (kp_B, desc_B) = self.computeSIFT(image_list[image_B_index])\n",
    "                    \n",
    "                        # Get valid matches\n",
    "                        matches = self.match_keypoints(kp_A, kp_B, desc_A, desc_B, low_ratio=0.7)\n",
    "                    \n",
    "                        if matches is None:\n",
    "                            continue\n",
    "                    \n",
    "                        (point_A, point_B, valid_match, valid_match_idx) = matches   \n",
    "\n",
    "                        draw = self.draw_matches(image_list[image_A_index], kp_A, image_list[image_B_index], kp_B, valid_match)\n",
    "                        \n",
    "                        cv2.imshow('Match draw', draw)\n",
    "                        cv2.waitKey(0)\n",
    "                        cv2.destroyAllWindows()\n",
    "\n",
    "                    # Compute homography, and Get perspective of image\n",
    "                    _, matched_mask = self.find_homography(image_list[image_A_index], image_list[image_B_index], homo_Threshold)\n",
    "                    \n",
    "                    if is_percent:\n",
    "                        percent = self.find_matches_percent(matched_mask)\n",
    "                        # print(f'A image index: {image_A_index} <-> {image_B_index}: B image index | matching percent: {percent}')\n",
    "\n",
    "                        if percent > percent_Threshold:\n",
    "                            match_count += 1\n",
    "\n",
    "                        if percent < 10: break\n",
    "\n",
    "                    else:\n",
    "                        num_of_inliers = self.find_inlier_matches(matched_mask)\n",
    "                        # print(f'A image index: {image_A_index} <-> {image_B_index}: B image index | number of inliers : {num_of_inliers}')\n",
    "\n",
    "                        if num_of_inliers > inlier_Threshold:\n",
    "                            match_count += 1\n",
    "\n",
    "                if max_count < match_count:\n",
    "                    max_match_index = image_A_index\n",
    "                    max_count = match_count \n",
    "\n",
    "            # print(f'index:{image_A_index} image be matching {match_count} images')\n",
    "\n",
    "        # print(f'max matched image index: {max_match_index}, count: {max_count}')\n",
    "\n",
    "        return max_match_index\n",
    "\n",
    "\n",
    "    def warp_perspective(self, src, dst, H):\n",
    "        warpped_image = cv2.warpPerspective(dst, H, ((src.shape[1] + dst.shape[1]), dst.shape[0]))\n",
    "\n",
    "        return warpped_image\n",
    "        \n",
    "    \n",
    "    def panorama_stitching(self, refer, pano, pano_draw_match_pair):\n",
    "        if pano_draw_match_pair:\n",
    "            # Compute SIFT\n",
    "            (kp_A, desc_A) = self.computeSIFT(refer)\n",
    "            (kp_B, desc_B) = self.computeSIFT(pano)\n",
    "        \n",
    "            # Get valid matches\n",
    "            matches = self.match_keypoints(kp_A, kp_B, desc_A, desc_B, low_ratio=0.7)\n",
    "        \n",
    "            if matches is None:\n",
    "                pass\n",
    "        \n",
    "            (point_A, point_B, valid_match, valid_match_idx) = matches   \n",
    "\n",
    "            draw = self.draw_matches(refer, kp_A, pano, kp_B, valid_match)\n",
    "            \n",
    "            cv2.imshow('Match draw', draw)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        h_r, w_r, _ = refer.shape\n",
    "        h_p, w_p, _ = pano.shape\n",
    "\n",
    "        H, _ = self.find_homography(pano, refer)\n",
    "\n",
    "        points = np.float32([[0, 0], [0, h_r - 1], [h_r - 1, h_r - 1], [h_r - 1, 0]]).reshape(-1, 1, 2)\n",
    "\n",
    "        P_Trans_corner_points = cv2.perspectiveTransform(points, H)\n",
    "\n",
    "        min_x1 = min(P_Trans_corner_points[0][0][0], P_Trans_corner_points[1][0][0])\n",
    "        min_x2 = min(P_Trans_corner_points[2][0][0], P_Trans_corner_points[3][0][0])\n",
    "        min_y1 = min(P_Trans_corner_points[0][0][1], P_Trans_corner_points[1][0][1])\n",
    "        min_y2 = min(P_Trans_corner_points[2][0][1], P_Trans_corner_points[3][0][1])\n",
    "\n",
    "        max_x1 = max(P_Trans_corner_points[0][0][0], P_Trans_corner_points[1][0][0])\n",
    "        max_x2 = max(P_Trans_corner_points[2][0][0], P_Trans_corner_points[3][0][0])\n",
    "        max_y1 = max(P_Trans_corner_points[0][0][1], P_Trans_corner_points[1][0][1])\n",
    "        max_y2 = max(P_Trans_corner_points[2][0][1], P_Trans_corner_points[3][0][1])\n",
    "\n",
    "        min_x = min(min_x1, min_x2)\n",
    "        min_y = min(min_y1, min_y2)\n",
    "        max_x = max(max_x1, max_x2)\n",
    "        max_y = max(max_y1, max_y2)\n",
    "\n",
    "        # Transformation matrix\n",
    "        T_matrix = np.eye(3)\n",
    "        \n",
    "        if min_x < 0:\n",
    "            max_x = w_p - min_x\n",
    "            T_matrix[0][2] = -min_x\n",
    "        else:\n",
    "            if max_x < w_p:\n",
    "                max_x = w_p\n",
    "\n",
    "        if min_y < 0:\n",
    "            max_y = h_p - min_y\n",
    "            T_matrix[1][2] = -min_y\n",
    "        else:\n",
    "            if max_y < h_p:\n",
    "                max_y = h_p\n",
    "        \n",
    "        warpped_refer = cv2.warpPerspective(refer, T_matrix, (int(max_y), int(max_x)), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "        panorama = cv2.warpPerspective(pano, np.dot(T_matrix, H), (int(max_y), int(max_x)), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "\n",
    "        warpped_refer_sum = warpped_refer.sum(axis=-1)\n",
    "        h_p1, w_p1 = warpped_refer_sum.shape\n",
    "\n",
    "        for h in range(h_p1 - 1):\n",
    "            for w in range(w_p1 - 1):\n",
    "                if warpped_refer_sum[h, w] > 0:\n",
    "                    panorama[h, w, :] = warpped_refer[h, w, :]\n",
    "\n",
    "        # panorama[0:warpped_refer.shape[0], 0:warpped_refer.shape[1]] = warpped_refer\n",
    "\n",
    "        return panorama\n",
    "    \n",
    "\n",
    "    def panorama_auto_stitching(self, pano, refer):\n",
    "        pano = cv2.resize(pano, (600, 450))\n",
    "        pano = cv2.resize(refer, (600, 450))\n",
    "        \n",
    "        H, _ = self.find_homography(pano, refer)\n",
    "\n",
    "        warpped = self.warp_perspective(pano, refer, H)\n",
    "        warpped[0:refer.shape[0], 0:refer.shape[1]] = refer\n",
    "\n",
    "        # Audo Stitcher\n",
    "        stitcher = cv2.Stitcher.create(cv2.Stitcher_PANORAMA)\n",
    "        _, pano = stitcher.stitch(pano, warpped)\n",
    "        \n",
    "        return pano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images: 8\n",
      "number of images: 7\n",
      "number of images: 6\n",
      "number of images: 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\RCV\\RCV\\week0912_panorama\\panorama_stitch.ipynb 셀 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/RCV/RCV/week0912_panorama/panorama_stitch.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     images\u001b[39m.\u001b[39mappend(cv2\u001b[39m.\u001b[39mimread(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(image_path, image)))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/RCV/RCV/week0912_panorama/panorama_stitch.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m panorama \u001b[39m=\u001b[39m Panorama()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/RCV/RCV/week0912_panorama/panorama_stitch.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m pano_image \u001b[39m=\u001b[39m panorama\u001b[39m.\u001b[39;49mimage_stitching(images)\n",
      "\u001b[1;32mc:\\Users\\RCV\\RCV\\week0912_panorama\\panorama_stitch.ipynb 셀 4\u001b[0m in \u001b[0;36mPanorama.image_stitching\u001b[1;34m(self, images, low_ratio, homo_Threshold, percent_Threshold, inlier_Threshold, is_percent, draw_matches, pano_draw_match_pair)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/RCV/RCV/week0912_panorama/panorama_stitch.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     panorama \u001b[39m=\u001b[39m max_matched_image\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/RCV/RCV/week0912_panorama/panorama_stitch.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39melse\u001b[39;00m:    \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/RCV/RCV/week0912_panorama/panorama_stitch.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     panorama \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpanorama_stitching(max_matched_image, panorama, pano_draw_match_pair)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/RCV/RCV/week0912_panorama/panorama_stitch.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mpanorama\u001b[39m\u001b[39m'\u001b[39m, panorama)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/RCV/RCV/week0912_panorama/panorama_stitch.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m0\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\RCV\\RCV\\week0912_panorama\\panorama_stitch.ipynb 셀 4\u001b[0m in \u001b[0;36mPanorama.panorama_stitching\u001b[1;34m(self, refer, pano, pano_draw_match_pair)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/RCV/RCV/week0912_panorama/panorama_stitch.ipynb#W3sZmlsZQ%3D%3D?line=258'>259</a>\u001b[0m     draw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdraw_matches(refer, kp_A, pano, kp_B, valid_match)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/RCV/RCV/week0912_panorama/panorama_stitch.ipynb#W3sZmlsZQ%3D%3D?line=260'>261</a>\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mMatch draw\u001b[39m\u001b[39m'\u001b[39m, draw)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/RCV/RCV/week0912_panorama/panorama_stitch.ipynb#W3sZmlsZQ%3D%3D?line=261'>262</a>\u001b[0m     cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/RCV/RCV/week0912_panorama/panorama_stitch.ipynb#W3sZmlsZQ%3D%3D?line=262'>263</a>\u001b[0m     cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/RCV/RCV/week0912_panorama/panorama_stitch.ipynb#W3sZmlsZQ%3D%3D?line=264'>265</a>\u001b[0m h_r, w_r, _ \u001b[39m=\u001b[39m refer\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    image_list = os.listdir(image_path)\n",
    "\n",
    "    images = []\n",
    "    for image in image_list:\n",
    "        images.append(cv2.imread(os.path.join(image_path, image)))\n",
    "\n",
    "    panorama = Panorama()\n",
    "    \n",
    "    pano_image = panorama.image_stitching(images)\n",
    "\n",
    "    # cv2.imwrite(os.path.join(save_path, 'pano_result.jpg'), pano_image)\n",
    "    # cv2.imshow('panorama image', pano_image)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "107e91d575181c488c64d8bf21e5536a1f13671eba2eb8c493305a976f753f73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
